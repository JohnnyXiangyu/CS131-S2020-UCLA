\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}

% to be able to draw some self-contained figs
\usepackage{tikz}
\usepackage{amsmath}

% inlined bib file
\usepackage{filecontents}

%-------------------------------------------------------------------------------
\begin{document}
%-------------------------------------------------------------------------------

%don't want date printed
\date{}

% make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Java Concurrency Experiments Report}

%for single author (just remove % characters)
\author{
{\rm Xiangyu Wan}\\
UCLA
% copy the following lines to add more authors
% \and
% {\rm Name}\\
%Name Institution
} % end author

\maketitle


%-------------------------------------------------------------------------------
\section{AcmeSafeState Implementation Explained}
%-------------------------------------------------------------------------------

The AcmeSafeState class I implemented uses AtomicLongArray class provided in java.util.concurrent.atomic package and comes from modifying SynchronizedState. 
Changes include declaring what used to be a long[] member as a AtomicLongArray, and changing all array getting and setting statements to corresponding AtomicLongArray methods.
These atomic access methods include AtomicLongArray.length(), to get length, AtomicLongArray.get(), to get a certain value by subscript, and AtomicLongArray.getAndIncrement()/getAndDecrement() which takes the element by subscript and increment/decrements it.
Then the synchronized keyword is taken off from swap() method.

The main difference between AcmeSafeState and SynchronizedState is that, one uses the synchronized functionality provided by JVM, while the other uses Atomic operations.
As defined in the Lea paper, a block marked with "synchronized" by default uses builtin locks to enforce execution order.
Such usage of multual exclusive locks result in blocking and waking in addition to R/A mode access to the lock itself, and extra overhead is brought about.

On the other hand, AcmeSafeState uses atomic operations, which is implementation of the Volatile mode as mentioned in Lea's paper. 
In an AtomicLongArray, elements must be updated atomically, as mentioned in its own documentation, meaning that each operation is totally independent from another, they cannot interrupt each other.
Therefore, it's volatile mode because atomic operations form a total order: any 2 atomic operation cannot have the same level of precedence. 
When multiple threads are running, a total ordering on operations prevents data racing on each element of this atomic array, since 2 operations on the single element can't have same level of precedence.
The resulting AcmeSafeState class is thus data-race-free.

%-------------------------------------------------------------------------------
\section{Problems Encountered}
%-------------------------------------------------------------------------------

Since each test has to be done on both of 2 servers choosing from SEASnet servers, the first problem I encountered was on how to gather system information.
Much of the information provided in /proc/cpuinfo and /proc/meminfo are too detailed for this project. 
Eventually I decided to include number of processors, by counting lines starting with "processor" in /proc/cpuinfo using grep and wc commands, 
and total memory, by grep the line starting with "MemTotal" in /proc/meminfo, with a shell script.
The next problem was limited resource. For some reason, as I later figured out, server 10 only allows me to use 4 processors, so tests running 40 threads are unable to proceed.
Moving to server 07 solved it, though I initially thought this was caused by overwhelmed server capacity.

%-------------------------------------------------------------------------------
\section{Measurements}
%-------------------------------------------------------------------------------

Each item in the table is total real time, in seconds, reported by each of the 96 test harnesses.
\begin{enumerate}
  \item   
  On lnxsrv07:
  \begin{enumerate}
    \item 
    Synchronized
    \begin{center}
      \begin{tabular}{|c|c|c|c|}
      \hline
        Threads/Size & 5 & 100 & 114514 \\
      \hline 1 & 2.40645 & 2.30248 & 2.44090 \\
      \hline 8 & 41.8353 & 46.7085 & 59.6889 \\
      \hline 30 & 44.2645 & 50.3885 & 58.5530 \\
      \hline 40 & 58.0985 & 49.1583 & 57.5134 \\
      \hline
      \end{tabular}
    \end{center}
    \item 
    Null
    \begin{center}
      \begin{tabular}{|c|c|c|c|}
      \hline
        Threads/Size & 5 & 100 & 114514 \\
      \hline 1 & 1.67645 & 1.48559 & 1.24514 \\
      \hline 8 & 0.456103 & 0.485669 & 0.578254 \\
      \hline 30 & 0.342519 & 0.414552 & 0.504577 \\
      \hline 40 & 0.463978 & 0.528948 & 0.447990 \\
      \hline
      \end{tabular}
    \end{center}
    \item 
    Unsynchronized
    \begin{center}
      \begin{tabular}{|c|c|c|c|}
      \hline
        Threads/Size & 5 & 100 & 114514 \\
      \hline 1 & 1.74454 & 1.65491 & 1.64390 \\
      \hline 8 & 5.05006! & 4.96911! & 0.890892! \\
      \hline 30 & 2.93315! & 3.39934! & 0.731315! \\
      \hline 40 & 2.84386! & 3.06318! & 0.841629! \\
      \hline
      \end{tabular}
    \end{center}
    \item 
    AcmeSafe 
    \begin{center}
      \begin{tabular}{|c|c|c|c|}
      \hline
        Threads/Size & 5 & 100 & 114514 \\
      \hline 1 & 2.79151 & 2.90863 & 4.08026 \\
      \hline 8 & 15.5459 & 4.11677 & 1.76787 \\
      \hline 30 & 10.8118 & 5.53087 & 0.926240 \\
      \hline 40 & 8.49417 & 3.42478 & 0.835697 \\
      \hline
      \end{tabular}
    \end{center}
  \end{enumerate}

  \item   
  On lnxsrv09:
  \begin{enumerate}
    \item 
    Synchronized
    \begin{center}
      \begin{tabular}{|c|c|c|c|}
      \hline
        Threads/Size & 5 & 100 & 114514 \\
      \hline 1 & 2.09573 & 2.06913 & 2.36986 \\
      \hline 8 & 23.4730 & 20.0931 & 25.2516 \\
      \hline 30 & 23.9477 & 27.1043 & 32.8053 \\
      \hline 40 & 25.0529 & 25.5896 & 32.7916 \\
      \hline
      \end{tabular}
    \end{center}
    \item 
    Null
    \begin{center}
      \begin{tabular}{|c|c|c|c|}
      \hline
        Threads/Size & 5 & 100 & 114514 \\
      \hline 1 & 1.39438 & 1.34573 & 1.33739 \\
      \hline 8 & 0.269665 & 0.297212 & 0.297726 \\
      \hline 30 & 0.239610 & 0.301251 & 0.289336 \\
      \hline 40 & 0.485659 & 0.420304 & 0.547376 \\
      \hline
      \end{tabular}
    \end{center}
    \item 
    Unsynchronized
    \begin{center}
      \begin{tabular}{|c|c|c|c|}
      \hline
        Threads/Size & 5 & 100 & 114514 \\
      \hline 1 & 1.54024 & 1.51304 & 1.92184 \\
      \hline 8 & 2.47085! & 4.25720! & 0.848775! \\
      \hline 30 & 2.76206! & 3.00428! & 0.739111! \\
      \hline 40 & 2.84741! & 3.09914! & 0.818826! \\
      \hline
      \end{tabular}
    \end{center}
    \item 
    AcmeSafe 
    \begin{center}
      \begin{tabular}{|c|c|c|c|}
      \hline
        Threads/Size & 5 & 100 & 114514 \\
      \hline 1 & 2.64326 & 2.63030 & 4.00808 \\
      \hline 8 & 5.47784 & 7.53352 & 1.70335 \\
      \hline 30 & 5.45605 & 4.82547 & 0.938191 \\
      \hline 40 & 9.01959 & 4.45131 & 0.832072 \\
      \hline
      \end{tabular}
    \end{center}
  \end{enumerate}
\end{enumerate}


% describe Synchronized and AcmeSafe performance.

It's observed on both servers that AcmeSafe class has overall better performance than SynchronizedState.
Since the only difference is the use of synchronized keyword and atomic array, it should be the cause in the different performance. 
As mentioned above, atomic arrays order operations in a Volatile order.
Each atomic operation on a same element in the array are ensured by hardware to operate sequentially.
This is the strongest order mode mentioned in Lea's article.
According to Lea, the tradeoff of stronger modes is losing parallelism.
Operations that could run in parallel in weaker modes may run sequentially in stronger modes.

Locks, however, introduce overhead that's byond the scope of memory order modes, said Lea in the Locks section of his paper.
By using synchronized keyword to declare a method, inherently a lock is used to eliminate data race.
Operations on the lock itself is under Release/Acquire mode, which is a weaker mode than Volatile and should have more parallelism.
This lock, implemented in a mutex lock mannar as indicated by Lea, requires blocking and waking threads.
In this case, the overhead introduced by blocking exceeds the influence of ordering, as shown by the slower operation of Synchronized class than AcmeSafe.

%-------------------------------------------------------------------------------
\bibliographystyle{plain}
\bibliography{\jobname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%  LocalWords:  endnotes includegraphics fread ptr nobj noindent
%%  LocalWords:  pdflatex acks